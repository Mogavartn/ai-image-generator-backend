#!/usr/bin/env python3
"""
G√©n√©rateur d'Images IA - Version all√©g√©e pour Render Free
Optimis√© pour 512MB RAM
"""

import os
import json
import time
import tempfile
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Optional

import torch
from flask import Flask, request, jsonify, send_file
from flask_cors import CORS
from werkzeug.utils import secure_filename

# Import conditionnel des librairies lourdes
try:
    import safetensors.torch as st
    SAFETENSORS_AVAILABLE = True
except ImportError:
    SAFETENSORS_AVAILABLE = False
    print("‚ö†Ô∏è  Safetensors non disponible")

# Import diffusers seulement si n√©cessaire
DIFFUSERS_AVAILABLE = False

app = Flask(__name__)
CORS(app, origins=['https://webinterface-imageai.onrender.com'])

# Configuration ultra-l√©g√®re
app.config.update(
    MAX_CONTENT_LENGTH=50 * 1024 * 1024,  # 50MB max
    UPLOAD_FOLDER=tempfile.mkdtemp(prefix="ai_lite_"),
    RESULTS_FOLDER="./generated_images",
    MAX_IMAGES=1,  # Une seule image max
    DEFAULT_STEPS=10,  # Steps tr√®s r√©duits
)

# Variables globales
temp_files = set()

class LightweightGenerator:
    """G√©n√©rateur ultra-l√©ger pour plan gratuit"""
    
    def __init__(self):
        self.device = "cpu"  # Forc√© CPU pour le plan gratuit
        self.temp_dir = Path(app.config['UPLOAD_FOLDER'])
        self.results_dir = Path(app.config['RESULTS_FOLDER'])
        self.results_dir.mkdir(exist_ok=True)
        
        print(f"üñ•Ô∏è  Device: {self.device}")
        print(f"üìÅ Mode ultra-l√©ger activ√©")
    
    def validate_safetensors(self, file_path: Path) -> bool:
        """Validation minimale"""
        try:
            if not SAFETENSORS_AVAILABLE:
                # Validation basique par taille de fichier
                size_mb = file_path.stat().st_size / (1024 * 1024)
                if size_mb < 0.1 or size_mb > 5000:  # Entre 100KB et 5GB
                    return False
                print(f"üìä Fichier: {size_mb:.1f}MB (validation basique)")
                return True
            
            # Validation compl√®te si safetensors disponible
            st.load_file(str(file_path))
            return True
        except Exception as e:
            print(f"‚ùå Validation √©chou√©e: {e}")
            return False
    
    def generate_mock_images(self, 
                           prompt: str,
                           num_images: int = 1,
                           dimensions: str = "512x512") -> List[Dict]:
        """G√©n√©ration d'images simul√©e pour les tests"""
        
        print(f"üé® G√©n√©ration simul√©e: {prompt}")
        
        results = []
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        for i in range(min(num_images, 1)):  # Max 1 image en gratuit
            try:
                # Simuler un temps de g√©n√©ration
                time.sleep(2)  # 2 secondes de simulation
                
                # Cr√©er une image de test (placeholder)
                from PIL import Image, ImageDraw, ImageFont
                
                width, height = map(int, dimensions.split('x'))
                
                # Cr√©er une image simple
                img = Image.new('RGB', (width, height), color='lightblue')
                draw = ImageDraw.Draw(img)
                
                # Ajouter du texte
                text_lines = [
                    "Image g√©n√©r√©e",
                    f"Prompt: {prompt[:30]}...",
                    f"Dimensions: {dimensions}",
                    f"Mode: Simulation"
                ]
                
                y_offset = height // 4
                for line in text_lines:
                    try:
                        draw.text((10, y_offset), line, fill='black')
                        y_offset += 30
                    except:
                        pass  # Si police non disponible
                
                # Sauvegarder
                filename = f"generated_{timestamp}_{i+1:03d}.png"
                image_path = self.results_dir / filename
                img.save(str(image_path))
                
                results.append({
                    "filename": filename,
                    "path": str(image_path),
                    "dimensions": dimensions,
                    "generation_time": 2.0,
                    "url": f"/api/image/{filename}",
                    "mode": "simulation"
                })
                
                print(f"‚úÖ Image simul√©e cr√©√©e: {filename}")
                
            except Exception as e:
                print(f"‚ùå Erreur simulation: {e}")
                results.append({
                    "error": str(e),
                    "index": i+1
                })
        
        return results
    
    def generate_real_images(self, model_path: Path, **kwargs) -> List[Dict]:
        """G√©n√©ration r√©elle (si ressources suffisantes)"""
        
        # V√©rifier la m√©moire disponible
        import psutil
        memory_percent = psutil.virtual_memory().percent
        
        if memory_percent > 80:
            raise ValueError("M√©moire insuffisante pour la g√©n√©ration r√©elle")
        
        # Import dynamique de diffusers
        try:
            global DIFFUSERS_AVAILABLE
            if not DIFFUSERS_AVAILABLE:
                print("üì• Chargement de diffusers...")
                from diffusers import FluxPipeline
                DIFFUSERS_AVAILABLE = True
            
            # Charger le mod√®le (tr√®s lourd pour plan gratuit)
            print(f"üîÑ Chargement mod√®le: {model_path}")
            pipeline = FluxPipeline.from_pretrained(
                str(model_path),
                torch_dtype=torch.float32,  # CPU
                device_map=None
            )
            
            # G√©n√©ration (tr√®s lente sur CPU)
            print("üé® G√©n√©ration en cours...")
            # ... logique de g√©n√©ration r√©elle
            
        except Exception as e:
            print(f"‚ùå G√©n√©ration r√©elle impossible: {e}")
            raise ValueError(f"G√©n√©ration r√©elle √©chou√©e: {e}")

# Instance globale
generator = LightweightGenerator()

@app.route('/api/generate', methods=['POST'])
def generate_images():
    """Endpoint all√©g√© de g√©n√©ration"""
    try:
        print("üì® Nouvelle requ√™te (mode l√©ger)")
        
        # Validation basique
        if 'model_file' not in request.files:
            return jsonify({"success": False, "error": "Fichier mod√®le requis"}), 400
        
        model_file = request.files['model_file']
        if not model_file.filename:
            return jsonify({"success": False, "error": "Nom de fichier invalide"}), 400
        
        # Sauvegarder le fichier
        filename = secure_filename(model_file.filename)
        model_path = generator.temp_dir / f"model_{int(time.time())}_{filename}"
        model_file.save(str(model_path))
        temp_files.add(str(model_path))
        
        # Validation
        if not generator.validate_safetensors(model_path):
            return jsonify({"success": False, "error": "Fichier invalide"}), 400
        
        # Param√®tres
        prompt = request.form.get('prompt', '').strip()
        if not prompt:
            return jsonify({"success": False, "error": "Prompt requis"}), 400
        
        dimensions = request.form.get('dimensions', '512x512')
        
        # Mode de g√©n√©ration selon les ressources
        try:
            # Essayer g√©n√©ration r√©elle si possible
            results = generator.generate_real_images(
                model_path=model_path,
                prompt=prompt,
                dimensions=dimensions
            )
            mode = "real"
        except Exception as e:
            print(f"‚ö†Ô∏è  G√©n√©ration r√©elle impossible: {e}")
            # Fallback vers simulation
            results = generator.generate_mock_images(
                prompt=prompt,
                dimensions=dimensions
            )
            mode = "simulation"
        
        # Filtrer les succ√®s
        successful_results = [r for r in results if 'error' not in r]
        
        return jsonify({
            "success": True,
            "images": successful_results,
            "total_generated": len(successful_results),
            "mode": mode,
            "message": "G√©n√©ration en mode simulation (plan gratuit)" if mode == "simulation" else "G√©n√©ration r√©elle"
        })
        
    except Exception as e:
        print(f"‚ùå Erreur serveur: {e}")
        return jsonify({"success": False, "error": str(e)}), 500

@app.route('/api/image/<filename>')
def serve_image(filename):
    """Servir les images"""
    try:
        image_path = generator.results_dir / secure_filename(filename)
        if image_path.exists():
            return send_file(str(image_path))
        return jsonify({"error": "Image non trouv√©e"}), 404
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/cleanup', methods=['POST'])
def cleanup_temp_files():
    """Nettoyage ultra-l√©ger"""
    try:
        cleaned = 0
        for file_path in list(temp_files):
            try:
                if os.path.exists(file_path):
                    os.unlink(file_path)
                    cleaned += 1
                temp_files.discard(file_path)
            except:
                pass
        
        return jsonify({
            "success": True,
            "cleaned_files": cleaned,
            "message": f"{cleaned} fichiers nettoy√©s"
        })
    except Exception as e:
        return jsonify({"success": False, "error": str(e)}), 500

@app.route('/api/status')
def get_status():
    """Status ultra-l√©ger"""
    try:
        import psutil
        memory = psutil.virtual_memory()
        
        return jsonify({
            "status": "online",
            "device": generator.device,
            "mode": "lightweight",
            "memory_percent": memory.percent,
            "memory_available_mb": memory.available // (1024*1024),
            "safetensors_available": SAFETENSORS_AVAILABLE,
            "diffusers_available": DIFFUSERS_AVAILABLE,
            "temp_files": len(temp_files)
        })
    except Exception as e:
        return jsonify({"status": "error", "error": str(e)}), 500

@app.route('/')
def index():
    """Page simple"""
    return '''
    <!DOCTYPE html>
    <html>
    <head><title>G√©n√©rateur IA - Mode L√©ger</title></head>
    <body>
        <h1>üé® G√©n√©rateur d'Images IA - Mode L√©ger</h1>
        <p>Backend optimis√© pour plan gratuit Render</p>
        <ul>
            <li><a href="/api/status">Status</a></li>
            <li>Mode: Simulation + g√©n√©ration r√©elle si possible</li>
            <li>Optimis√©: 512MB RAM, CPU uniquement</li>
        </ul>
    </body>
    </html>
    '''

if __name__ == '__main__':
    print("üöÄ D√©marrage mode ultra-l√©ger")
    print(f"üíæ M√©moire: Plan gratuit (512MB)")
    print(f"üîß Safetensors: {'‚úÖ' if SAFETENSORS_AVAILABLE else '‚ùå'}")
    
    port = int(os.getenv('PORT', 5000))
    app.run(host='0.0.0.0', port=port, debug=False)