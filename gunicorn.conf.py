# gunicorn.conf.py - Configuration optimisÃ©e pour Render Free
import os

# Configuration pour plan gratuit Render (0.1 CPU, 512MB RAM)
bind = f"0.0.0.0:{os.environ.get('PORT', 5000)}"

# Un seul worker pour Ã©conomiser la RAM
workers = 1
worker_class = "sync"
worker_connections = 10

# Timeouts adaptÃ©s au plan gratuit
timeout = 600  # 10 minutes pour gÃ©nÃ©ration d'images
keepalive = 2
max_requests = 50  # RedÃ©marrer le worker aprÃ¨s 50 requÃªtes
max_requests_jitter = 10

# Gestion mÃ©moire
worker_memory_limit = 400 * 1024 * 1024  # 400MB limite par worker
preload_app = True  # PrÃ©charger l'app pour Ã©conomiser RAM

# Logs
loglevel = "info"
accesslog = "-"
errorlog = "-"
access_log_format = '%(h)s %(l)s %(u)s %(t)s "%(r)s" %(s)s %(b)s "%(f)s" "%(a)s" %(D)s'

# Optimisations pour dÃ©marrage
pythonpath = "/opt/render/project/src"

def when_ready(server):
    """Callback exÃ©cutÃ© quand le serveur est prÃªt"""
    print("ğŸš€ Serveur Gunicorn prÃªt - Plan Free Render")
    print(f"ğŸ’¾ RAM limite: {worker_memory_limit // (1024*1024)}MB par worker")

def worker_exit(server, worker):
    """Cleanup quand un worker se ferme"""
    print(f"ğŸ”„ Worker {worker.pid} fermÃ© - libÃ©ration mÃ©moire")
    
    # Nettoyage mÃ©moire PyTorch
    try:
        import torch
        if hasattr(torch.cuda, 'empty_cache'):
            torch.cuda.empty_cache()
        import gc
        gc.collect()
    except:
        pass